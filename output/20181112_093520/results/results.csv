,action_description,action_id,attrib,driver,element_selector,method_name,open_url,retry_count,selector_type,sendkeys_text,test_folder,wait,error,js_log,method,return_value,timestamp
0,Open web scraper test page,1,,"<selenium.webdriver.chrome.webdriver.WebDriver (session=""8a2c16e37750e98628308ce2fe4cc518"")>",,get_url,https://github.com/blchadick,5,,,output/20181112_093520/,5,,[],get_url,action successful,2018-11-12 09:35:27.144000
1,,4,,"<selenium.webdriver.chrome.webdriver.WebDriver (session=""8a2c16e37750e98628308ce2fe4cc518"")>",//article,get_element_text,,3,xpath,,output/20181112_093520/,3,,[],get_element_text,"scraping-tool
Overview:
This script utilizes the Selenium Python library and Webdriver to automate crawling of websites, including responsive web applications. A sequence of actions is fed into the script as a CSV file. The script executes those actions, returning the results of their executions and a screenshot. Specific elements within a page can be targeted by either specifying xPath or CSS selectors. The following methods are implemented in the latest iteration of the script.
METHOD: DESCRIPTION
get_url: Navigates to a specified URL
get_element_text: Gets the text value of a specified element
get_element_attrib: Returns the attribute value of a specified element and attribute
action_element_click: Clicks on a specified element
action_element_sendkeys: Enters text into a specified element
send_keys_submit: Enters text into a specified element and presses the return key",2018-11-12 09:35:50.390000
